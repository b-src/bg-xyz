# A Guide to Hosting a Gemini Capsule on a VPS

While this guide is meant to be as beginner friendly as possible, it is important to note up front that there are inherent risks and responsibilities associated with running and maintaining a server that is connected to the internet. I've done my best to provide guidance on best practices for security, but this is limited by my own knowledge and I am far from an expert. I welcome corrections and additional advice.

## What is a VPS?

VPS stands for Virtual Private Server. It is a virtual machine running on somebody else's physical server. The box running your VPS will also be running many others. Virtual machines provide isolation from the host machine, meaning nobody with a VPS that is running on the same physical machine is able to access your VPS. This is true so long as an attacker does not have an exploit called a virtual machine escape.

=> https://en.wikipedia.org/wiki/Virtual_machine_escape   The Wikipedia page on virtual machine escapes. Includes a list of publicly disclosed virtual machine escapes.

## Choosing a VPS

There are many VPS providers available. If you google it you will find piles of guides on choosing a VPS host, written by the VPS hosts themselves for the sake of SEO.

I like DigitalOcean. They have a nice interface, they have instances starting at $4 per month, and they are reliable. Depending on your bandwidth and compute load you may be able to get away with a free-tier instance from one of the major cloud providers.

### Some VPS Hosts

=> https://www.digitalocean.com DigitalOcean

=> https://aws.amazon.com AWS (Amazon Web Services)

=> https://azure.microsoft.com Azure (Microsoft)

=> https://cloud.google.com GCP (Google Cloud Platform. Could be shuttered at any moment if google gets bored)

## Choosing an Operating System

Your VPS provider likely has many OS images available. Important considerations are:
 * can you run the Gemini server you intend to use on the OS?
 * how familiar are you with the particular OS and its tools, e.g. its package manager?
 * is it stable? (don't pick arch)
 * does it get timely security updates?
 * don't use Windows Server

Major linux distros are probably all fine choices.

## Registering a domain name

TODO

## Creating an SSH key

SSH keys are an example of asymmetrical cryptography, which uses a pair of keys: one public and one private. Messages that are encrypted using the public key can only be decrypted using the private key. Public keys can be shared, while private keys should NEVER be shared.

Using ssh keys for user authentication provides more security than relying on passwords.

Here is a command using ssh-keygen which will generate a new key pair at the location specified by -f using the algorithm specified by -t.

``` command line instruction for generating an ssh key
 $ ssh-keygen -t ed25519 -f ~/.ssh/<my_key_name>
```

This command will create two files: a private key at ~/.ssh/<my_key_name>, and a public key at ~/.ssh/<my_key_name>.pub


## Launching your Instance

The instructions in this section will be based on DigitalOcean, but the steps should broadly be the same across cloud providers. I will try to stick to general terms as opposed to DigitalOcean specific terms, e.g. "instance" instead of "droplet"

From your VPS provider's dashboard:
 * select an instance size
 * select a base image/OS
 * select a region
 * if possible, provide your public ssh key at the time of instance creation
 * launch the instance

## Logging into your Instance

Connect to the instance via ssh

``` command line instruction for connecting to your instance via ssh
 $ ssh root@<instance.ip>
```

## Securing your Instance

### Create a non-root user to log in with

``` command line instruction for creating a new user
 $ useradd <username>
```

You will be prompted for a password. Choose a strong, unique, randomly generated password.

Add the user to the sudoers group

``` command line instruction for adding a user to the sudoers group
 $ usermod -aG sudo <username>
```

On some linux distros the sudoers group is called 'wheel' rather than 'sudo'.

Enable ssh login for the new user. If you provided a public key at the time of instance creation, you will just need to copy the .ssh directory to the new user's home directory 

``` command line instruction for enabling ssh login for the new user
 $ rsync --archive --chown=<username>:<username> ~/.ssh /home/<username>
```

### Log in as the new user

Exit your original ssh session. Log in again, this time specifying your new user account

``` command line instruction for connecting to your instance via ssh with a non-root user account
 $ ssh <username>@<instance.ip>
```

Once you're able to log in with the new user account you're ready to begin locking down your instance.

### Disable root login and password authentication

``` command line instruction for editing the sshd_config file
 $ sudo vim /etc/ssh/sshd_config
```

Find the PermitRootLogin setting. Change the value from yes to no.

Find the PasswordAuthentication setting. Change the value from yes to no. If you were able to supply your public key at the time of instance creation, this may already be set to no

Save your changes. The ssh daemon must be restarted for your changes to take effect.

``` command line instruction for restarting the sshd service
 $ sudo systemctl reload sshd
```

As a fun exercise, check the authentication log to see how many attempted logins you've had since spinning up your instance

``` command line instruction for printing the authentication log
 $ sudo cat /var/log/auth.log
```


### Update packages to latest versions

Instructions shown are for Ubuntu. Substitute the package manager commands for your chosen distro as needed.

``` command line instructions for upgrading packages on Ubuntu
 $ sudo apt update
 $ sudo apt upgrade
```

### Lock down unused ports

To see what ports are listening you can use a tool like lsof

``` command line instruction for listing listening ports
 $ sudo lsof -i -P -n | grep LISTEN
```

At this point you should see sshd on port 22 and systemd-resolved on port 53. sshd is what allows you to ssh into your server. systemd-resolved handles outbound dns resolution. You will want to leave both of these enabled. If you see additional ports enabled you will want to investigate and disable them if they aren't needed.

### Configure firewall rules

This section will show the commands to configure a firewall using iptables. A more detailed breakdown of iptables can be found here:

=> iptables.gmi iptables

iptables rules can be viewed by running

``` command line instruction to list iptables rules
 $ sudo iptables -vnL --line-numbers
```

Set firewall rules to allow outbound DNS lookups (needed to allow package manager to function). These commands will need to be repeated for each DNS server you are using. See the iptables article linked above for help figuring out which servers you are using for DNS.

``` command line instructions for configuring iptables rules to allow outbound DNS lookups
 $ sudo iptables -A OUTPUT -p udp -d <dns.server.ip.address> --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT
 $ sudo iptables -A OUTPUT -p tcp -d <dns.server.ip.address> --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT
 $ sudo iptables -A INPUT -p udp -s <dns.server.ip.address> --sport 53 -m state --state ESTABLISHED -j ACCEPT
 $ sudo iptables -A INPUT -p tcp -s <dns.server.ip.address> --sport 53 -m state --state ESTABLISHED -j ACCEPT
```

Set firewall rules to allow all localhost traffic

```
 $ sudo iptables -A INPUT -i lo -j ACCEPT
 $ sudo iptables -A OUTPUT -o lo -j ACCEPT
```

Set firewall rules to allow http and https traffic to and from package repositories (needed to allow package manager to function). These commands will need to be repeated for each package repo you are using. Depending on the repo you may need to also enable FTP traffic on port 21. See the iptables article linked above for help figuring out which package repo servers you need to enable.

``` command line instructions for configuring iptables rules to allow traffic to a package repo
 $ sudo iptables -A OUTPUT -p tcp -d "<package.repo>" --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT
 $ sudo iptables -A OUTPUT -p tcp -d "<package.repo>" --dport 443 -m state --state NEW,ESTABLISHED -j ACCEPT
 $ sudo iptables -A INPUT -p tcp -s "<package.repo>" --sport 80 -m state --state ESTABLISHED -j ACCEPT
 $ sudo iptables -A INPUT -p tcp -s "<package.repo>" --sport 443 -m state --state ESTABLISHED -j ACCEPT
```

Set firewall rules to allow ssh traffic (port 22)

``` command line instruction for configuring iptables rule to allow ssh traffic
 $ sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT
 $ sudo iptables -A OUTPUT -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT
```


Set firewall rule to allow http traffic (port 80)

``` command line instruction for configuring iptables rule to allow https traffic
 $ sudo iptables -A INPUT -p tcp --dport 80 -j ACCEPT
 $ sudo iptables -A OUTPUT -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT

```

Set firewall rule to allow https traffic (port 443)

``` command line instruction for configuring iptables rule to allow https traffic
 $ sudo iptables -A INPUT -p tcp --dport 443 -j ACCEPT
 $ sudo iptables -A OUTPUT -p tcp --sport 443 -m state --state ESTABLISHED -j ACCEPT

```

Set firewall rule to allow gemini traffic (port 1965)

``` command line instruction for configuring iptables rule to allow gemini traffic
 $ sudo iptables -A INPUT -p tcp --dport 1965 -j ACCEPT
 $ sudo iptables -A OUTPUT -p tcp --sport 1965 -m state --state ESTABLISHED -j ACCEPT

```

iptables -A OUTPUT -p udp -m udp --dport 53 -j ACCEPT
Set firewall rules to drop all other traffic

``` command line instruction for configuring iptables rule to drop other traffic
 $ sudo iptables -A INPUT -j DROP
 $ sudo iptables -A FORWARD -j DROP
 $ sudo iptables -A OUTPUT -j DROP

```

At this point list the iptables rules again with the following command.

``` command line instruction to list iptables rules
 $ sudo iptables -vnL --line-numbers
```

Save your iptables rules

``` command line instruction to save iptables rules
 $ sudo iptables-save > /etc/iptables/rules.v4
```

Enable automatic iptables rules loading on boot by installing the iptables-persistent package

``` command line instruction to install iptables-persistent
 # sudo apt-get install iptables-persistent
```

## Deploying your Pages

### Install your gemini server

This process will look very different depending on the server you chose. The instructions in this section will be for agate.

=> gemini://qwertqwefsday.eu/agate.gmi

=> https://github.com/mbrubeck/agate

Download the precompiled binary. If you are following the instructions on this page directly, make sure to replace the url in the command with the latest release. Note that if you have configured your firewall as shown above you will not be able to run this curl command directly from your vps. In that case you will want to download the agate binary locally and copy it to your server using scp.

``` command line instruction for downloading a precompiled agate binary
 $ curl -L https://github.com/mbrubeck/agate/releases/download/v3.2.4%2Bbuild/agate.x86_64-unknown-linux-gnu.gz -O
```

Extract the binary from the .gz archive

``` command line instruction for extracting a .gz archive
 $ gunzip agate.x86_64-unknown-linux-gnu.gz
```

Copy the binary to /usr/local/bin and make it executable by the TODO user
TODO: fix permissions for the right user

``` command line instructions for local installation of agate
 $ sudo mkdir /usr/local/bin/agate
 $ sudo cp agate.x86_64-unknown-linux-gnu /usr/local/bin/agate/agate
 $ sudo chmod +x /usr/local/bin/agate/agate
```

### Deploy 

Create a directory for your gemtext files

``` command line instruction to make a directory for your gemtext files
 $ sudo mkdir -p /usr/share/agate/root
```

From your local machine, copy your gemtext files to the server
``` command line instruction to make a directory for your gemtext files
 $ scp -r my/local/content/dir <user>@<my.instance.ip>:<user/home/dir>
```

From your instance, copy the gemtext files to the directory you created previously
``` command line instruction to copy your gemtext files to the agate root directory
 $ cp -r <usr/home/dir/content> /usr/share/agate/root
```

Run agate
``` command line instruction to run the agate server
 $ /usr/local/bin/agate/agate --content /usr/share/agate/root --addr 0.0.0.0:1965 --hostname <hostname> --lang en-US
```

At this point you should be able to open your favorite gemini browser and navigate to your site at gemini://<hostname>. Note that agate expects your home page to be called `index.gmi`

If you can access your site, you know that the server is running and your firewall has been configured to allow gemini traffic. The next step is to create a systemd service for your server so that it will run automatically on server startup.

Create the file /etc/systemd/system/agate.service and add the following contents to it:

``` contents of the agate systemd service file
[Unit]
Description=Agate Gemini Server
After=systemd-resolved.service
StartLimitIntervalSec=0

[Service]
Type=simple
Restart=always
RestartSec=15
user=<service user>
ExecStart=/usr/local/bin/agate/agate --content /usr/share/agate/root --addr 0.0.0.0:1965 --hostname <hostname> --lang en-US

[Install]
WantedBy=multi-user.target
```

Start the service with:

``` command line instruction to start the gemini server service
 $ sudo systemctl start agate
```

Set the service to start on boot:

``` command line instruction to start the gemini server service
 $ sudo systemctl enable agate
```


### Install Nginx as a reverse proxy

``` command line instruction for installing nginx
 $ sudo apt install nginx
```

If you run the lsof command to list open ports, you should now see entries for port 80 for nginx.

If you open a web browser and navigate to http://<ip.of.your.instance>, you will see the default welcome page for nginx. Run the following commands to remove the default virtual host's symlink and restart the nginx service.

``` command line instructions for removing the nginx default virtual host's symlink
 $ sudo rm /etc/nginx/sites-enabled/default
 $ sudo systemctl restart nginx
```

Now refresh the browser page pointed at your ip and you will get a connection error.

Create a document root directory for your web content.

``` command line instruction for creating a document root dir for your web content
 $ sudo mkdir /usr/share/nginx/<www-root-dir-name>
```

<www-root-dir-name> can be whatever you like, so long as the config points to the right place later.

Create a virtual host file for the website

``` command line instruction for opening new virtual host file in a text editor
 $ sudo vim /etc/nginx/sites-available/<www-root-dir-name>
```

Add the following contents to the virtual host file

``` contents of the virtual host file for your website
server {
    listen 80 default_server;

    root /usr/share/nginx/<www-root-dir-name>;
    index index.html;

    server_name <www-root-dir-name> www.<www-root-dir-name>;
    location / {
        try_files $uri $uri/ /index.html;
    }
}
```

Create a symlink to the sites-enabled directory

``` command line instruction to create a symlink to your site configuration under the sites-enabled directory from the sites-available directory
 $ sudo ln -s /etc/nginx/sites-available/<www-root-dir-name> /etc/nginx/sites-enabled/<www-root-dir-name>
```

Test that your configuration file syntax is okay

``` command line instruction to test nginx config syntax
 $ sudo nginx -t
```

Restart nginx

``` command line instruction to restart the nginx service
 $ sudo systemctl restart nginx
```

#### Add https

Install certbot

``` command line instruction to install certbot
 $ sudo apt install certbot python3-certbot-nginx
```

Generate ssl cert

```
 $ sudo certbot --nginx -d brettgleason.xyz -d www.brettgleason.xyz
```

You will be asked to enter an email address, agree to the letsencrypt terms of service, and whether you want to allow your email to be shared with the EFF.

Certbot will automatically update your nginx server config. Any line that was changed by certbot will be appended with "# managed by Certbot"

Certbot will also handle certificate renewal. The command to generate the ssl certificate also adds a systemd timer that will run certbot twice a day. Normally no action is taken, but if your certificate is within 30 days of expiration, certbot will automatically renew your certificate.


=> https://creativecommons.org/licenses/by-nc-sa/4.0/    The content of this website is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)
